{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "if not 'workbookDir' in globals():\n",
    "    workbookDir = os.getcwd()\n",
    "\n",
    "to_remove = []\n",
    "d_to_remove = workbookDir\n",
    "for i, p in enumerate(sys.path):\n",
    "    try:\n",
    "        if p == \"\":\n",
    "            to_remove.append(i)\n",
    "        elif os.path.samefile(p, d_to_remove):\n",
    "            to_remove.append(i)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for i in reversed(to_remove):\n",
    "    try:\n",
    "        sys.path.pop(i)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "sys.path.insert(0, os.path.expanduser(\"~/onnxruntime/build_rocm/Release/build/lib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import onnx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ort.set_default_logger_severity(0)\n",
    "ort.set_default_logger_verbosity(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinormal_distribution(num_distribution, num_element_per_dist):\n",
    "    arrays = []\n",
    "    for i in range(num_distribution):\n",
    "        mean = np.random.randn()\n",
    "        std = np.random.rand() # * np.sqrt(num_element_per_dist)\n",
    "        arrays.append(np.random.normal(mean, std, (num_element_per_dist,)))\n",
    "    return np.array(arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_attn_bias = True\n",
    "use_attn_mask = False\n",
    "\n",
    "input = onnx.helper.make_tensor_value_info(\"input\", onnx.TensorProto.FLOAT16, [\"batchsize\", 512, 768])\n",
    "output = onnx.helper.make_tensor_value_info(\"output\", onnx.TensorProto.FLOAT16, [\"batchsize\", 512, 768])\n",
    "attn_mask = onnx.helper.make_tensor_value_info(\"attn_mask\", onnx.TensorProto.INT32, [\"batchsize\", 512])\n",
    "attn_bias = onnx.helper.make_tensor_value_info(\"attn_bias\", onnx.TensorProto.FLOAT16, [\"batchsize\", 12,  512, 512])\n",
    "\n",
    "np.random.seed(1)\n",
    "# qkv_weight_data = np.ones((768, 3 * 768))\n",
    "qkv_weight_data = multinormal_distribution(3*768 * 12, 768 // 12).reshape((768, 3 * 768))\n",
    "qkv_weight = onnx.helper.make_tensor(\"qkv_weight\", onnx.TensorProto.FLOAT16, [768, 2304], qkv_weight_data)\n",
    "# qkv_bias = onnx.helper.make_tensor(\"qkv_bias\", onnx.TensorProto.FLOAT16, [2304], np.random.random([2304]))\n",
    "qkv_bias = onnx.helper.make_tensor(\"qkv_bias\", onnx.TensorProto.FLOAT16, [2304], np.zeros([2304]))\n",
    "\n",
    "node_inputs = [\"input\", \"qkv_weight\", \"qkv_bias\", \"\", \"\", \"\"]\n",
    "if use_attn_bias:\n",
    "    node_inputs[5] = attn_bias.name\n",
    "if use_attn_mask:\n",
    "    node_inputs[3] = attn_mask.name\n",
    "node = onnx.helper.make_node(\"Attention\", inputs=node_inputs, outputs=[\"output\"], domain=\"com.microsoft\", num_heads=12)\n",
    "\n",
    "\n",
    "graph_inputs = [input]\n",
    "if use_attn_bias:\n",
    "    graph_inputs.append(attn_bias)\n",
    "if use_attn_mask:\n",
    "    graph_inputs.append(attn_mask)\n",
    "graph = onnx.helper.make_graph([node], \"Attn\", graph_inputs, [output], initializer=[qkv_weight, qkv_bias])\n",
    "\n",
    "model = onnx.helper.make_model(graph, producer_name=\"tmp\", opset_imports=[\n",
    "    onnx.helper.make_opsetid('com.microsoft', 1), \n",
    "    onnx.helper.make_opsetid('ai.onnx.ml', 1), \n",
    "    onnx.helper.make_opsetid('', 14),\n",
    "])\n",
    "\n",
    "print(onnx.checker.check_model(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(qkv_weight_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so = ort.SessionOptions()\n",
    "so.log_severity_level = 0\n",
    "so.log_verbosity_level = 1000\n",
    "\n",
    "sess0 = ort.InferenceSession(\n",
    "    model.SerializeToString(),\n",
    "    providers=[(\"CPUExecutionProvider\", {\"tunable_op_enabled\": \"0\"})],\n",
    "    sess_options=so,\n",
    ")\n",
    "\n",
    "sess1 = ort.InferenceSession(\n",
    "    model.SerializeToString(),\n",
    "    providers=[(\"ROCMExecutionProvider\", {\"tunable_op_enabled\": \"1\"})],\n",
    "    sess_options=so,\n",
    ")\n",
    "\n",
    "i = 17\n",
    "results = [{'ep': 'ROCMExecutionProvider', 'results': {'onnxruntime::TunableOp<onnxruntime::contrib::rocm::GemmSoftmaxGemmPermuteParams<__half>, onnxruntime::rocm::tunable::Timer>': {'M512_N512_K64_O64_B768': i}, 'onnxruntime::TunableOp<onnxruntime::rocm::tunable::blas::StridedBatchedGemmParams<__half>, onnxruntime::rocm::tunable::Timer>': {'NN_512_64_512_B768': 0, 'NT_512_512_64_B768': 0}, 'onnxruntime::TunableOp<onnxruntime::rocm::tunable::blas::GemmParams<__half>, onnxruntime::rocm::tunable::Timer>': {'NN_32768_2304_768': 0, 'NN_32768_2304_1': 0}}, 'validators': {'ORT_VERSION': '1.15.0', 'ORT_GIT_COMMIT': '', 'ORT_BUILD_CONFIG': 'USE_CK=1|USE_ROCBLAS_EXTENSION_API=0|', 'HIP_VERSION': '50422803', 'ROCBLAS_VERSION': '2.46.0.ef7a9bb9-dirty', 'DEVICE_MODEL': 'AMD Instinct MI250X/MI250'}}]\n",
    "# sess1.set_tuning_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "\n",
    "input = (0.01 * np.random.randn(batchsize, 512, 768)).astype(np.float16)\n",
    "# input = (0.01 * np.ones((batchsize, 512, 768))).astype(np.float16)\n",
    "\n",
    "attn_bias = np.random.uniform(-2, 2, size=(batchsize, 12, 512, 512)).astype(np.float16)\n",
    "# attn_bias[0,0,0,0] = float(\"nan\")\n",
    "\n",
    "\n",
    "attn_mask = np.ones([batchsize, 512], dtype=np.int32)\n",
    "# attn_mask[1, 1] = 2\n",
    "# attn_mask = np.zeros([batchsize, 512], dtype=np.int32)\n",
    "# attn_mask = np.random.randint(0, 2, size=(batchsize, 512), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feed = { \"input\": input }\n",
    "if use_attn_bias:\n",
    "    input_feed[\"attn_bias\"] = attn_bias\n",
    "if use_attn_mask:\n",
    "    input_feed[\"attn_mask\"] = attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o0 = sess0.run(\n",
    "    output_names = [node.name for node in sess0.get_outputs()],\n",
    "    input_feed = input_feed\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1 = sess1.run(\n",
    "    output_names = [node.name for node in sess1.get_outputs()],\n",
    "    input_feed = input_feed\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = o0\n",
    "my = o1\n",
    "diff = ref - my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(my[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(ref[i][-2])\n",
    "plt.plot(my[i][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my[i][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(my).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(ref).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denorm = ref.copy()\n",
    "denorm[denorm == 0] = float(\"inf\")\n",
    "rtol = np.abs(diff / denorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtol_1d = rtol.reshape(-1)\n",
    "\n",
    "print(np.sum(rtol_1d < 1))\n",
    "print(np.sum(rtol_1d >= 1))\n",
    "\n",
    "_ = plt.hist(rtol_1d[np.isfinite(rtol_1d)], bins=500, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
